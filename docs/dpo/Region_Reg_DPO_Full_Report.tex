\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{xeCJK}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{float}
\usepackage{longtable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue}

\lstset{
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{gray},
  stringstyle=\color{red},
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny\color{gray},
  showstringspaces=false,
  tabsize=4,
  language=Python,
}

\newtheorem{definition}{定义}[section]
\newtheorem{proposition}{命题}[section]
\newtheorem{remark}{注记}[section]

\title{\textbf{Region-Reg-DPO 与 DiffuEraser 深度融合\\完整技术报告（零基础可读版）}}
\author{技术深度解析}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
本报告对 Region-Reg-DPO（分区正则化直接偏好优化）与视频补全模型 DiffuEraser 的融合方案进行全链路深度解析。为了让初次接触该领域的读者也能轻松理解，本报告对“幽灵问题”、“幻觉”、“光流先验”等专业术语进行了通俗解释，并对晦涩的数学推导补充了直观的物理意义与详细的前进推导步骤。

报告从 DiffuEraser 当前工程痛点出发，系统推导 Region-Reg-DPO 的完整数学理论，详述 DPO 高质量偏好数据集的生成方案，论证融合可行性，并给出分步实施路线图与超参调优策略。所有技术细节均与项目真实代码实现相互印证。
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{引言：什么是视频补全与现有技术的痛点}
%==============================================================================

\textbf{视频补全（Video Inpainting）}的核心任务是：在视频画面中抠掉一块区域（比如移除画面中的路人、去掉视频水印等），然后让 AI 模型把这个“洞”合理地补全。补全的结果必须同时满足两个条件：
\begin{enumerate}
    \item \textbf{空间合理}：补出来的内容看起来像真实世界的物品，不能是奇形怪状的色块。
    \item \textbf{时间一致}：视频是连续播放的帧，补出来的内容在前后帧之间必须连贯，不能闪烁或抖动。
\end{enumerate}

当前业界主要有两条技术路线来解决这个问题，但它们各自面临着困境：

\begin{enumerate}
    \item \textbf{光流传播（Optical Flow Propagation）}：以 ProPainter模型 为代表。
    \begin{itemize}
        \item \textbf{通俗解释}：光流就像是视频中像素的“移动轨迹”。如果一个背景在第 1 帧被挡住了，但在第 10 帧露出来了，模型就顺着移动轨迹，把第 10 帧的背景“搬运”回第 1 帧补上。
        \item \textbf{痛点}：如果一个背景在整个视频里\textbf{一直}被挡住（全遮挡区域），模型就没东西可搬运了，只能把边缘的颜色往里涂抹，导致生硬的\textbf{模糊色块}。
    \end{itemize}
    \item \textbf{生成式扩散模型（Diffusion Models）}：以 DiffuEraser模型 为代表。
    \begin{itemize}
        \item \textbf{通俗解释}：这是目前最火的生成式 AI 技术。就算没有参考，模型也能根据学习到的海量知识“无中生有”，自己画出合理的背景。
        \item \textbf{痛点}：模型太有想象力了，并且缺乏时间和空间上的约束，容易产生\textbf{幻觉（凭空画出不存在的东西）}、\textbf{频闪（前后帧画的东西不一样）}以及\textbf{幽灵问题（没擦干净原物体）}。
    \end{itemize}
\end{enumerate}

本报告的核心，就是引入一种名为 \textbf{Region-Reg-DPO}（分区偏好优化）的新技术，来彻底驯服具有强大生成能力的 DiffuEraser 模型。

%==============================================================================
\section{DiffuEraser 当前的三大工程痛点深度解析}
%==============================================================================

\subsection{1. 文本提示的语义困境，以及为什么“无字胜有字”}

DiffuEraser 基于 Stable Diffusion，天然支持输入一段文字（Prompt）来告诉模型画什么。但在实际的物体移除（Object Removal）任务中，文字反而会坏事。

\begin{itemize}
    \item \textbf{不够精确}：如果我们要移除草地上的一只狗，用文字写“绿色的草地”，模型只能画出一块普通的草地，但这块草地的纹理、光影很可能与画面中原本的草地衔接不上。文字描述的是\textbf{全局的、粗粒度}的语义，无法指导\textbf{局部的、像素级}的纹理延伸。
    \item \textbf{引出幻觉}：如果你不小心写了“树木”，模型很可能在草地中间极其突兀地凭空画一棵树出来，这就叫\textbf{“幻觉”（Hallucination）}。
    \item \textbf{代码实证}：工程实践证明，在物体移除任务中，什么都不提示（设定 \texttt{guidance\_scale=0} 也就是完全取消无分类器引导），让模型纯粹依靠周围环境的视觉特征去推理，反而能获得最自然的修补效果。
\end{itemize}

在代码层面，\texttt{diffueraser\_OR.py} 中 \texttt{guidance\_scale} 被强行设为 0：
\begin{lstlisting}
# DiffuEraser_new/diffueraser/diffueraser_OR.py
# 2-Step 模式对应索引 [2]，即 0.0
self.guidance_scale = checkpoints[ckpt][2]  
\end{lstlisting}

\subsection{2. “幽灵问题”与 Mask掩膜的双刃剑效应}

**什么是“幽灵问题”（Ghosting）？** 
当我们框选出画面中的一只狗（这个指示框出的黑白图就是 Mask掩膜），告诉模型：“把 Mask 里面的狗删掉”。结果模型虽然把狗的细节抹去了，但在这个位置留下了一个模糊的、狗形状的阴影。就好像狗变成了幽灵一样。

\textbf{产生原因}：
Mask 实际上向模型泄露了“这里曾经有个什么形状的物体”。神经网络喜欢“顺着轮廓作画”。在原本的 DiffuEraser 设计中，为了把边缘修补得更好，使用了数学形态学的方法把 Mask 进行“膨胀”（让需要修补的洞变大一点）：
\begin{lstlisting}
# diffueraser_OR_DPO.py 中对 Mask 进行了人为放大
m = cv2.dilate(m, cv2.getStructuringElement(
    cv2.MORPH_RECT, (3, 3)),
    iterations=mask_dilation_iter)
\end{lstlisting}
这不仅导致模型看到了“扩大的轮廓”，还使得修补后的画面和外面原本的真实画面产生了拼接缝隙。

\subsection{3. 缺乏时空保护导致的“频闪”（Flickering）}

\begin{itemize}
    \item \textbf{高可见性区域的破坏}：就像前面所说，有些区域原本是用光流技术“搬运”周围帧就能完美解决的，但扩散模型不管这些，它就是要“再画一次”。这一画，反而把原本清晰真实的像素变成了有噪点、不稳定的生成像素。
    \item \textbf{时间上的不连贯}：扩散模型独立地画第一帧、第二帧。即便加入了一些时空模块，如果不加以严格奖惩，它很容易在第 1 帧画一块石头，在第 2 帧画一团草。快速播放时，观众看到的就是剧烈闪烁的“频闪”。
\end{itemize}

\textbf{破局点：DPO（直接偏好优化）}。如果模型经常画出“幽灵”和“频闪”，我们就直接制作一批“很烂的视频”和一批“完美的真实视频”同时扔给模型，强迫模型说：\textbf{你如果像左边这么画，我就惩罚你；你必须朝着右边完美视频的方向作画。} 这就是 DPO 要做的事情。

%==============================================================================
\section{理论基础：从标准 DPO 到 Region-Reg-DPO}
%==============================================================================

初次引入 DPO 遇到了极大的数学障碍，导致模型经常训练崩溃。为了让初学者理解，这里我们把所有的数学推导补充了极其详尽的“大白话”翻译和推导过渡环节。

\subsection{符号定义与大白话翻译}

\subsubsection{一帧画面切三块：三区 Mask 分解}

我们不能把 DPO 奖惩一股脑加给整张图，因为图中不同区域的需求是完全不一样的。

\begin{definition}[三区空间划分]
将视频帧空间严格分为三个不相交区域：
\begin{enumerate}
    \item \textbf{洞内区域 $\mathbf{R_h}$（对应 Mask 为 $\mathbf{M_h}$）}：这是我们要抠掉并重画的地方，这里允许模型发挥想象力去补全背景。
    \item \textbf{边界带 $\mathbf{R_b}$（对应 Mask 为 $\mathbf{M_b}$）}：紧贴着“洞”外侧的一圈窄带（大概 5~15 像素宽）。\textbf{这里极度重要！} 它是生成内容与真实世界的拼接缝。这里必须和真实世界一模一样，否则就会有裂缝！此区域通过将 $M_h$ 膨胀后再减去自己得到：$M_b = \text{Dilate}(M_h, k) - M_h$。
    \item \textbf{上下文区域 $\mathbf{R_c}$（对应 Mask 为 $\mathbf{M_c}$）}：剩下的全部安全区域，这里是完全没有任何修改的真实视频，模型绝对不可以碰这里。
\end{enumerate}
这三个区域加在一起拼成了完整的画面：$M_h + M_b + M_c = 1$。
\end{definition}

\subsubsection{谁是正样本（Win），谁是负样本（Lose）？}

\begin{itemize}
    \item \textbf{正样本（Win，记作 $\mathbf{w}$）}：就是原始的、没有被任何遮挡的真实视频。这是给模型学习的“完美答案”。模型基于它预测的噪声记作 $\epsilon^w$。
    \item \textbf{负样本（Lose，记作 $\mathbf{l}$）}：就是我们故意用很差的模型生成的、包含幽灵和闪烁的“垃圾视频”。这是告诉模型“千万别这么画”的反面教材。模型基于它预测的噪声记作 $\epsilon^l$。
\end{itemize}

\subsection{普通 DPO 的致命缺陷：为什么一训练就死？}

如果用公式表达 DPO 让模型比拼好坏的过程，核心是一个叫 $s(\theta)$ 的分数差值：
$$s(\theta) = \text{正样本相较于参考模型的误差改善} - \text{负样本的误差改善}$$

模型的任务是通过更新自身参数（$\theta$）去把这个 $s(\theta)$ 变小（甚至变成极小的负数）。但是，更新参数所使用的力度（梯度）会受到一个衰减函数的控制：
$$\text{更新力度 (DGR)} = \frac{\beta'}{1 + e^{-\beta' \cdot s(\theta)}}$$

\textbf{大白话解释这个致命推导：}\\
假设一开始 $s(\theta)=0$（好坏不分），更新力度 DGR 大概是 $\frac{1000}{2}=500$（很大）。\\
一旦模型变聪敏了一丁点，把 $s(\theta)$ 降到了 $-0.01$。分母上的 $e^{-\beta' \cdot s(\theta)}$ 变成了 $e^{10} \approx 22026$！\\
此时：$\text{更新力度 (DGR)} = \frac{1000}{1 + 22026} \approx 0.045$。\\
\textbf{结论：模型才刚学会一丁点好坏之分，更新力度就暴跌了 11000 倍！} 模型瞬间“僵死”，再也不学习了，这就是著名的\textbf{梯度消失}灾难。

不仅如此，洞里面（$M_h$）面积大，模型很容易就在洞里学到了微小的改善，导致全图的更新力度 DGR 暴跌。此时，那圈窄窄的、最容易出接缝问题的\textbf{边界带（$\mathbf{M_b}$）完全还没来得及学习}，就没有力度更新了！

\subsection{我们提出的创新：Region-Reg-DPO（双轮驱动防御）}

为了打破这个僵局，我们提出了修改梯度，给原本的更新公式强行加上一个“不随 DGR 衰减的保底工资” $\rho_r$：

\begin{table}[H]
\centering
\caption{双权重机制（大白话翻译）}
\begin{tabular}{@{}llp{8cm}@{}}
\toprule
权重代号 & 扮演角色 & 大白话解释 \\
\midrule
$\mathbf{\alpha_r}$ & 偏好学习权重 & 教模型“哪个好哪个坏”。它的力度会随着模型越变越聪明而急剧缩小直至归零（受 DGR 致命衰减控制）。 \\
$\mathbf{\rho_r}$ & SFT 锚定常数 & 教模型“你必须长得像真实的一样”。\textbf{这个力度是铁饭碗常量，永远不会衰减！} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{最核心的五步推导：怎么把“保底工资”反向变回公式}

由于我们在神经网络里没法直接改“更新力度（梯度）”，我们需要通过微积分\textbf{反推}出：到底要往原始的 Loss（损失函数）里加一项什么数学公式，才能在求导之后，恰好在末端得到这个“保底工资” $\rho_r$？

这就需要进行严密的五步反推逻辑：

\textbf{Step 1：写出我们想要的理想梯度（力求各区不仅有缩减的偏好指导，还有保底的 SFT 锚定）。}
$$\nabla_\theta \mathcal{L}_{\text{修改}} = -\mathbb{E}\bigg[\sum_r 2\Big\{\underbrace{(\alpha_r \cdot \text{DGR} + \rho_r)}_{\text{正样本有双重指导}} \cdot \big(\cdots \nabla_\theta \epsilon_\theta^w\big) - \underbrace{\alpha_r \cdot \text{DGR}}_{\text{负样本只有偏好惩罚}} \cdot \big(\cdots \nabla_\theta \epsilon_\theta^l\big)\Big\}\bigg]$$

\textbf{Step 2：将上述公式剥离提取。}
把它拆成原本随 DGR 衰减的 Part 1（原版 DPO）和新加的保底项 Part 2：
$$\text{Part 2 (附加项)} = -\mathbb{E}\bigg[\sum_r 2\rho_r \cdot \big(M_r \odot (\epsilon^w - \epsilon_\theta^w)\big)^T \nabla_\theta \epsilon_\theta^w\bigg]$$

\textbf{Step 3：使用微积分寻找原函数（逆向演算）。}
留意到，任何求带有掩膜的平方误差的导数满足：
$$\nabla_\theta \|M_r \odot (\epsilon^w - \epsilon_\theta^w)\|^2 = -2\big(M_r \odot (\epsilon^w - \epsilon_\theta^w)\big)^T \nabla_\theta \epsilon_\theta^w$$
对比 Step 2 可以惊奇地发现，Part 2 这个多出来的部分，**恰好就是对带有区域权重 $\rho_r$ 的正样本均方误差进行求导的结果！**

\textbf{Step 4：拼装完整的终极损失函数。}
只要我们在原始的 DPO Loss 后面，直接加一项这个求导前的均方误差（SFT 正则化），就能完美实现我们的设计：
$$\boxed{\mathcal{L}_{\text{Region-Reg-DPO}} = \underbrace{-\mathbb{E}\Big[\log \sigma\big(-\beta' \cdot s_{\text{region}}(\theta)\big)\Big]}_{\text{负责教好坏（偏好优化）}} + \underbrace{\mathbb{E}\bigg[\sum_{r \in \{h,b,c\}} \rho_r \cdot \|M_r \odot (\epsilon^w - \epsilon_\theta^w)\|^2\bigg]}_{\text{负责保底锚定（防崩溃的铁饭碗）}}}$$

\textbf{通过这个极度优美的数学推发，我们实现了三重稳定防御机制：}
\begin{enumerate}
    \item \textbf{不畏惧衰减}：哪怕 DGR 衰减归零了，后面的 SFT 保底依然以 $\rho_h$ / $\rho_b$ 的力度逼迫模型学习正样本。
    \item \textbf{坚固边界}：我们通过给边界区 $\mathbf{M_b}$ 分配极大的 $\rho_b$（如 200），让模型在边界带受到极强的惩罚，只要稍不吻合原图立刻修正。缝合处彻底没了残影。
    \item \textbf{堵死作弊漏洞}：模型无法通过把两边数值无脑膨大来糊弄差值了，因为 SFT 项会对绝对数值膨大进行无情惩罚。
\end{enumerate}


%==============================================================================
\section{融合可行性深度评估}
%==============================================================================

Region-Reg-DPO 与 DiffuEraser 系统能完美对接，可行性极高：

\begin{enumerate}
    \item \textbf{靶向修复“幽灵问题”}：原来的 DiffuEraser 在边界容易泄漏 Mask 轮廓，现在通过 $M_h$ 区的惩罚机制，强行拉开“包含幽灵的生成图”和“干净的原图”评分，从根本上杜绝了幽灵。
    \item \textbf{高级“潜空间”融合（Latent Space Blending）}：原技术只能在生图最终环节把两张图粗暴生冷地拼一块（就像贴双面胶）。新方案利用 $\mathbf{\rho_b}$ 在网络的最深处（潜空间）通过数学计算进行强制过度和融合，闪烁和缝隙自然消失。
    \item \textbf{无破坏性微调}：实施时，完全冻结原作者辛辛苦苦训练的主干，只使用一种名为 \textbf{LoRA（低秩自适应）}的轻量级技术附着在网络上微调（相当于只给大脑加一个小补丁），杜绝了对老模型基本功的破坏。
\end{enumerate}


%==============================================================================
\section{DPO 偏好数据集生成的工业级方案}
%==============================================================================

给 AI 上课（训练模型）拿不出教材（数据）是不行的。DPO 训练极其依赖“有对比的负面例子（Lose）”。项目现有的代码库（\texttt{generate\_dpo\_negatives.py}）实现了一套极其优雅的工业级方案。

\subsection{让模型修复陷入绝望的“困难 Mask”生成}
如果只是随机打一个小马赛克，光流技术很容易就能修好它，导致模型看不到“真正的烂例子”。因此，需要定制化刁难模型：
\begin{itemize}
    \item \textbf{强制面积占总画面的 40\%-50\%}：遮挡面积巨大，逼迫模型必须靠脑补，光流彻底失效。
    \item \textbf{强制中央位置且缓慢移动}：像真的有一座大山始终挡在屏幕中央跟着镜头慢移，周围像素完全没法借用。位置限制必须留下四周各 15\% 的“空气墙”防撞反弹。
\end{itemize}

\subsection{用三把不同毒药炼废出最烂的负样本（三管齐下）}
为了避免模型对特定的某种错漏产生偏好，我们准备了三种不同流派制作的最烂生成效果供它辨别：
\begin{enumerate}
    \item \textbf{模糊流（Blur）}：调用普通 ProPainter 工具，在那种大面积遮挡下，肯定会被糊成一坨大平涂色块。
    \item \textbf{幻觉流（Hallucination，关键代码）}：修改 DiffuEraser 的初始输入环节，\textbf{直接剥夺先验注入（代码里给 \texttt{priori=None}）}：
\begin{lstlisting}
def read_priori(priori, ...):
    if not priori:  # 如果强制传入空...
        return []   # 就不给任何参考视频，彻底抓瞎
\end{lstlisting}
    模型只能用纯高斯随机噪声硬算，这样必定会脑补出毫不相关的诡异静物（也就是严重的“幻觉”现象）。
    \item \textbf{频闪流（Flickering）}：让同一个原视频基于两个“不同的随机种子”（\texttt{seed=A} 和 \texttt{seed=B}）生出两个平行世界的幻觉，然后\textbf{每隔 8 帧剪切交替拼接到一起}（A8 帧 - B8 帧 - A8 帧）。生成的假视频就会发生瞎眼的剧烈高频闪烁。
\end{enumerate}

\subsection{防止被平均化的局部精密评分（16帧纵向缝合技术）}

\textbf{痛点揭露：}如果用一个评分器给一段长达 80 帧的视频打出一个综合总分。极可能发生一种情况——虽然视频总分全场垫底，但是在其中某一段 16 帧里表现其实还不赖。如果训练时恰好抽到了这不错的 16 帧，不就把给模型喂反面教材的目的给毁了吗？

\textbf{破局手段：}既然训练 DataLoader 每次喂模型进去的是 16 帧片段。那么我评分切割打分也必定精确对齐：
\begin{enumerate}
    \item 将 80 帧长度的上面那三类“毒药”视频通通以 16 帧为切块输入给 \texttt{InpaintingScorer} 打分引擎。
    \item 在第 1 块 16 帧比拼中，发现“幻觉流”最烂，取出这一段最烂的 16 帧。
    \item 在第 2 块 16 帧比拼中，发现“频闪流”最烂，同理取出。
    \item 直至终点，将取出的这些各段里的极品垃圾进行\textbf{横跨时间的无情缝合}，拼成一部漫长的全新负样本视频录入数据库。
    \item 这样无论 DataLoader 把手从哪个时间切入进去抓取 16 帧，抓到的必定是整个池子里最恶劣的那个反面案例，可谓是刀刀见血，避免了平均分带来的局部遮掩效应。
\end{enumerate}

值得一提的是，评分引擎 \texttt{InpaintingScorer} 并不是只看一两个数字的，它内置了包含对：画面美学、光影质量、运动平滑、以及背景一致性和时序稳定度多达六个维度的深度评判加权汇总才决出高下。


%==============================================================================
\section{从上马到投产的实施路线图（避坑指南）}
%==============================================================================

\subsection{Step 0：一切由数据定江山（优先级最高，耗时 3-4 周）}
运行 \texttt{generate\_dpo\_negatives.py} 生成海量的偏好正负视频对（至少 1000 组有效的 22 帧 clip 切片）。\\
\textbf{大坑预警}：绝对不能急着去改那一堆 Loss 和参数，负面教材如果跟原来的高清原图差距不够刺眼，后面再好的算法也学不出来。务必花大时间先确认这些自动生成的数据，其负样本是不是在视觉上的溃败是“肉眼可见、令人发指”的水平再说。

\subsection{Step 1：拆分组装切割机（0.5 周）}
实现 \texttt{region\_mask\_utils.py} 的形态学提取。把老版本单一打平的 Mask 精密剥离切分为我们数学模型预定义的 $M_h$, $M_b$, $M_c$ 三份。\\
\textbf{关键提示}：模型计算损失所在的时空叫 Latent（潜空间），此空间长宽尺寸只有原始外边视频呈现分辨率的 \textbf{八分之一}（除以8）。你在调整边界带扩张参数 $k$ 时，脑子里必须时刻挂起这八倍镜换算。

\subsection{Step 2：将数学公式落地写进脑子（1-2 周）}
建立 \texttt{region\_reg\_dpo\_loss.py} 开始照着第四个章节五步推推导的最后结果拼装：\\
\textbf{防崩溃护航}：刚刚进入 DPO 第一天，此时 $s(\theta)$ 还是0，前面那个衰减因子 DGR 将处于数值极度亢奋的状态。头一十几个 Step 会释放出极大概率击穿数值溢出的超大梯度（即初始的大型爆冲），必须强制使用 \texttt{Gradient Clipping（梯度裁剪保护）} 去兜住它，同时用 \texttt{F.logsigmoid} 函数代替硬套自然对数 $\log$，防爆内存溢出。 

\subsection{Step 3：组建微调军团 Stage 3 训练营（1 周）}
把原来的 \texttt{train\_DiffuEraser\_stage1.py} 回炉重造成专属于 DPO 训练版本的脚本。
引入之前提到的极其聪敏但又不伤底脑的 LoRA 微调挂件给主核（UNet），其他什么前置引导的 BrushNet 和动作协调器统通硬锁住（冻结）。模型每抓取一个数据进去，事实上相当于四条线在这个内存里穿插翻滚（新老模型 $\times$ 正负同测 = 单步骤就要跑4轮前向传输计算）。所以必须开启 \textbf{梯度记忆检查点}和利用 \textbf{CPU外借内存轮转} 这两大显存救命绝技把爆炸压下来。

\subsection{Step 4与5：极其抠门的投喂调参（3 周内出师验收）}
调参要有清心寡欲的方法论：
\begin{enumerate}
    \item \textbf{戒急戒躁}：先老老实实把保底工资项 $\rho$ 都归 0，就单飞最初的 DPO 公式进去跑，只要那条衰竭因子曲线 DGR 是顺滑溜走的没炸膛，就说明数学实现安全了。
    \item \textbf{重装挂载}：全体挂满 $\rho = 100$ 的数值看看崩溃度是不是极大改善？
    \item \textbf{区别对待}：边界上重注压狠手 $\rho_b = 200$，洞穴内部稍微放手一搏 $\rho_h=100$，看看那个烦人的画面接缝是不是一下子抹平了？
\end{enumerate}

%==============================================================================
\section{抄作业的超参数表与总结复盘}
%==============================================================================

\begin{table}[H]
\centering
\caption{Region-Reg-DPO 完整超参数拿来即用表}
\begin{tabular}{@{}llp{7cm}@{}}
\toprule
重点参数代号 & 全面体检过关预备值 & 人话大白话解释 \\
\midrule
$\alpha_h$ & 1.0 & 这个不用变，也就是洞内教好坏的基础学习基准。 \\
$\alpha_b$ & 1.5 $\sim$ 2.0 & 这个要加重！教给边界地带优先去敏锐鉴别烂画和好画的能力！ \\
$\alpha_c$ & 0.05 $\sim$ 0.1 & 外圈安全地带，不用投入太多鉴美资源，所以剥削力度极小。 \\
$\rho_h$ & 50 $\sim$ 150 & 洞内防止胡乱学崩盘设立的一个适当的“跟原图锁死度”。 \\
\textbf{$\rho_b$} & \textbf{100 $\sim$ 250 (全场最高)} & \textbf{生死接缝！绝不放过半点马虎的原画面死贴铁饭碗限制力度！} \\
学习率 (lr) & $1\times10^{-6} \sim 5\times10^{-6}$ & 要极其克制（步子小）。因为公式被两项强加码放大了，走大了就扯蛋了。 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{报告终于抵达尾声总结：}面对前所未有但又潜能爆表的生成式大视界修补工程。原本放任自流的模型总是给你画频闪，补出那些挥之不去的边缘幽灵残影。
\textbf{是 Region-Reg-DPO ，通过一套无懈可击的纯粹在 Latent（潜层空间）执行数学重构的五段式极限约束演进公式彻底勒住了缰绳。} 
在配备最前排通过三种极限花式（模糊、丢先验爆幻觉、狂按多种子爆闪烁）炮制出来的恶骨级反面训练特训大补数据套餐助攻之下。哪怕是个只拥有少许改动权利却身披防范内存爆破铠甲的 LoRA 挂件插件，在这个精心准备好防大冲刷削减因子保底保护层的新 SFT数学战甲支撑下。一定能在极短的一两个月验证周期内，打出一套丝滑毫无界域裂痕且拒绝鬼影残留跨代纪的工业级强时空视频还原作品！此路线从数学根基开始已毫无悬念的彻底跑通可行！

\end{document}
